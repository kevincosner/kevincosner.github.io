
<html>
    <head>
        <title> ScannerNet: A Deep Network for Scanner-Quality Document Images under Complex Illumination </title>
        <meta HTTP-EQUIV="Content-Type" CONTENT="text/html;charset=UTF-8">
        <link rel="icon" href="../../images/icon.png">
        <link href="../../css/style.css" rel="stylesheet">
    </head>
    
    <body>
        <div style="margin-left:auto; margin-right:auto; width:800">
        <h3 class="my-3">ScannerNet: A Deep Network for Scanner-Quality Document Images under Complex Illumination</h3>
        
        Chih-Jou Hsu<sup>1</sup> &nbsp;&nbsp;&nbsp;
        <a href="https://kevincosner.github.io/">Yu-Ting Wu</a><sup>2</sup> &nbsp;&nbsp;&nbsp;
        Ming-Sui Lee<sup>1</sup> &nbsp;&nbsp;&nbsp;
        <a href="http://www.csie.ntu.edu.tw/~cyy/">Yung-Yu Chuang</a><sup>1</sup>
    
        <br>
        <a href="http://www.ntu.edu.tw/">National Taiwan University</a><sup>1</sup> &nbsp;&nbsp;&nbsp;
        <a href="https://new.ntpu.edu.tw/">National Taipei University</a><sup>2</sup> &nbsp;&nbsp;&nbsp;
        <br>
        <br>
    
        <div><a href="images/teaser.png"><img class="img-fluid rounded" src="images/teaser.png" width=800></a></div>
        <div>
            <p>
            <b>Photometric distortion correction.</b> Our method is effective for correcting complex photometric distortions in document 
            images. The top row shows the images captured by cameras, and the bottom row shows the enhanced images produced using the 
            proposed method, which corrects shadows, shading, and color shift simultaneously.
            </p>
        </div>
    
        <hr class="style-two">
        <p>
        <font size=+1><b>Abstract</b></font><br>
        Document images captured by smartphones and digital cameras are often subject to photometric distortions, including shadows, 
        non-uniform shading, and color shift due to the imperfect white balance of sensors. Readers are confused by an indistinguishable 
        background and content, which significantly reduces legibility and visual quality. Despite the fact that real photographs often 
        contain a mixture of these distortions, the majority of existing approaches to document illumination correction concentrate on 
        only a small subset of these distortions. This paper presents ScannerNet, a comprehensive method that can eliminate complex 
        photometric distortions using deep learning. In order to exploit the different characteristics of shadow and shading, our model 
        consists of a sub-network for shadow removal followed by a sub-network for shading correction. To train our model, we also devise 
        a data synthesis method to efficiently construct a large-scale document dataset with a great deal of variation. Our extensive 
        experiments demonstrate that our method significantly enhances visual quality by removing shadows and shading, preserving figure 
        colors, and improving legibility.
        </p>
        <hr class="style-two">
    
        <p>
        <font size=+1><b>Publication</b></font><br>
        Chih-Jou Hsu, Yu-Ting Wu, Ming-Sui Lee, Yung-Yu Chuang. <br>
        ScannerNet: A Deep Network for Scanner-Quality Document Images under Complex Illumination. <br>
        Proceedings of British Machine Vision Conference (BMVC) 2022. <a href="citation.bib">BibTex</a><br>
        <a href="paper.pdf" target="_blank">BMVC 2022 Paper (13.6MB PDF)</a><br>
        <a href="https://bmvc2022.mpi-inf.mpg.de/345/" target="_blank">Digital library</a>    
        </p>
        <hr class="style-two">
    
        <p>
        <font size=+1><b>Supplemental</b></font><br>
        <a target="_blank" href="supplemental.pdf" >BMVC 2022 supplementary document (45.3MB PDF)</a><br>
        <a target="_blank" href="poster.pdf" >BMVC 2022 poster (2.6MB PDF)</a><br>
        </p>
        
        <br><br>
        <hr class="style-two">
        <p>Last Update: July 2021</p>

    </body>
</html>
    