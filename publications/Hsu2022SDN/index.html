
<html>
    <head>
        <title> ScannerNet: A Deep Network for Scanner-Quality Document Images under Complex Illumination </title>
        <meta HTTP-EQUIV="Content-Type" CONTENT="text/html;charset=UTF-8">
        <link rel="icon" href="../../images/icon.png">
        <link href="../../css/style.css" rel="stylesheet">
    </head>
    
    <body>
        <div style="margin-left:auto; margin-right:auto; width:800">
        <h3 class="my-3">ScannerNet: A Deep Network for Scanner-Quality Document Images under Complex Illumination</h3>
        
        Chih-Jou Hsu<sup>1</sup> &nbsp;&nbsp;&nbsp;
        <a href="https://kevincosner.github.io/">Yu-Ting Wu</a><sup>2</sup> &nbsp;&nbsp;&nbsp;
        Ming-Sui Lee<sup>1</sup> &nbsp;&nbsp;&nbsp;
        <a href="http://www.csie.ntu.edu.tw/~cyy/">Yung-Yu Chuang</a><sup>1</sup>
    
        <br>
        <a href="http://www.ntu.edu.tw/">National Taiwan University</a><sup>1</sup> &nbsp;&nbsp;&nbsp;
        <a href="https://new.ntpu.edu.tw/">National Taipei University</a><sup>2</sup> &nbsp;&nbsp;&nbsp;
        <br>
        <br>
    
        <div><a href="images/teaser.png"><img class="img-fluid rounded" src="images/teaser_preview.png" width=800></a></div>
        <div>
            <p>
            TBD.
            </p>
        </div>
    
        <hr class="style-two">
        <p>
        <font size=+1><b>Abstract</b></font><br>
        Document images captured by smartphones and digital cameras are often subject to photometric distortions, including shadows, 
        non-uniform shading, and color shift due to the imperfect white balance of sensors. Readers are confused by an indistinguishable 
        background and content, which significantly reduces legibility and visual quality. Despite the fact that real photographs often 
        contain a mixture of these distortions, the majority of existing approaches to document illumination correction concentrate on 
        only a small subset of these distortions. This paper presents ScannerNet, a comprehensive method that can eliminate complex 
        photometric distortions using deep learning. In order to exploit the different characteristics of shadow and shading, our model 
        consists of a sub-network for shadow removal followed by a sub-network for shading correction. To train our model, we also devise 
        a data synthesis method to efficiently construct a large-scale document dataset with a great deal of variation. Our extensive 
        experiments demonstrate that our method significantly enhances visual quality by removing shadows and shading, preserving figure 
        colors, and improving legibility.
        </p>
        <hr class="style-two">
    
        <p>
        <font size=+1><b>Publication</b></font><br>
        Chih-Jou Hsu, Yu-Ting Wu, Ming-Sui Lee, Yung-Yu Chuang. <br>
        ScannerNet: A Deep Network for Scanner-Quality Document Images under Complex Illumination. <br>
        Proceedings of British Machine Vision Conference (BMVC) 2022. <a href="citation.bib">BibTex</a><br>
        <a href="paper.pdf" target="_blank">BMVC 2022 Paper (13.6MB PDF)</a><br>
        <a href="">Digital library (Coming Soon!)</a>    
        </p>
        <hr class="style-two">
    
        <p>
        <font size=+1><b>Supplemental</b></font><br>
        <a target="_blank" href="supplemental.pdf" >HPG 2021 supplementary document (67.7MB PDF)</a><br>
        <a target="_blank" href="slides.pptx" >HPG 2021 presentation (11.2MB PPTX)</a><br>
        <a target="_blank" href="interactive_compare.html" >Web interactive comparison on synthetic data and Intel RealSense data</a><br>
        <a target="_blank" href="interactive_compare2.html">Web interactive comparison on Middlebury 2014 data</a>
        </p>
        
        <br><br>
        <hr class="style-two">
        <p>Last Update: July 2021</p>

    </body>
</html>
    